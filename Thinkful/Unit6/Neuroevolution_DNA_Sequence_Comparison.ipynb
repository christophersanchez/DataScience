{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA Sequence Comparison\n",
    "__October, 2018 - Christopher Sanchez__ \n",
    "\n",
    "A neuroevolution model will be created in order to compare DNA sequences. A genetic algorithm will be used to train a recurrent neural network to best determine similarity between sequences. The genetic algorithm will be utilized to determine the best weighting of the networks. The goal today is for the network to be effective at predicting similarity in order to infer homogeneity\n",
    "\n",
    "Deoxyribonucleic acid, or DNA is a double helix shaped structure consisting of a chain of nucleotides known as basepairs that act like a blueprint, providing a list of instructions for your body to create proteins. There are four distinct bases A, T, C and G. A always bonds with T and C always bonds with G. A wide variety of information can be gained from DNA analysis. It is possible to determine gender, disease susceptibility, familial ties, DNA is responsible for solving countless amounts of crime, and more! There are multiple sequencing techniques out there, but not all are great for error. I was inspired by this paper: https://www.cse.unr.edu/~cheung/neorgene.pdf, to attempt improving the dna sequencing techniques that are used today. There will be two genes used today one for training which is LOCUS NT_187300, and is 156,246 base pairs long. The other gene that will be used for testing is LOCUS NT_187301 and is 177,312 basepairs long. A LSTM RNN is perfect for the task, because it works well with error. A human genome consists of six billion basepairs mistakes are going to be made. It isn't uncommon for a basepair to get switched around. It is important to use a technique that can operate quickly and accurately. \n",
    "\n",
    "Genetic algorithms work by immitating Darwin's survival of the fittest theory. The survival of the fittest theory suggests that natural selection selects the best individuals and discards the weakest, thereby passing on only the strognest genes. Each sample is considered an individual. A population is all of the individuals together. A fitness score is used to determine how fit or weak an individual is. The best parents are used to breed and create individuals with characteristics of the parents. A mutation can be added to further improve on results. Finally evolution takes place combining all of the steps together to create the best offspring possible.\n",
    "\n",
    "Combining recurrent neural networks and a genetic algorithm is a quite interesting way to train the network. First the dna sequence must be cleaned and processed in order to be passed into the neural network. Once the sequence is processed and split into individuals the genetic algorithm will pass the individuals into the neural network using mean squared error as the fitness score in order to provide a grade to each network. Then the data will be bred and mutated in order to produce offspring and cause evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/c/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from operator import add, sub\n",
    "from numpy import argmax, array\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, TimeDistributed, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import bernoulli\n",
    "# Import the backend\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This total similarity function will be used to determine a similarity score for the tested data to compare with the output from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_similarity(similarity):\n",
    "    unique, counts = np.unique(similarity, return_counts=True)\n",
    "    total_similarity = dict(zip(unique, counts))\n",
    "    if False not in total_similarity:\n",
    "        total_similarity[False] = 0\n",
    "\n",
    "    if total_similarity[True] and total_similarity[False] > 0:\n",
    "        total_similarity = total_similarity[True].sum() / (total_similarity[False] + total_similarity[True])\n",
    "    elif total_similarity[False] == 0:\n",
    "        total_similarity = 1.0\n",
    "    else:\n",
    "        total_similarity = 0.0\n",
    "    return total_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error will act as a fitness function, and will also be useful for determining the accuracy of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    y_true = y_true.reshape(y_true.shape[0], y_true.shape[1])\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two functions will be used to create bargraphs in a more presentable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basepair_graph(data):\n",
    "    character_count = Counter(data)\n",
    "\n",
    "    labels, values = zip(*character_count.items())\n",
    "\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = .8\n",
    "\n",
    "    plt.bar(indexes, values, width)\n",
    "    plt.xticks(indexes + width * 0, labels)\n",
    "    plt.title('Count of Basepairs')\n",
    "    plt.xlabel('Basepairs')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def basepair_graph_comparison(sequence_one, sequence_two, width, ax=None):\n",
    "    sequence_one_count = Counter(sequence_one)\n",
    "    sequence_two_count = Counter(sequence_two)\n",
    "\n",
    "    labels_one, values_one = zip(*sequence_one_count.items())\n",
    "    labels_two, values_two = zip(*sequence_two_count.items())\n",
    "\n",
    "    indexes = np.arange(len(labels_one))\n",
    "\n",
    "    ax.bar(indexes, values_one, width);\n",
    "    ax.bar(indexes, values_two, width * .5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I: Importing and analyzing data\n",
    "The dna sequences contain numbers labeling the lines, multiple new lines and some whitespaces. The sequence is cleaned, and then a bar graph is used to show the distribution of the individual basepairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dna.txt', 'r') as myfile:\n",
    "  dna = myfile.read()\n",
    "dna_basepairs = dna\n",
    "dna_basepairs = re.sub(r'[0-9]([0-9])?([0-9])?([0-9])?([0-9])?([0-9])?', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\n', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\s+', '', dna_basepairs).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bd3a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "basepair_graph(dna_basepairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of basepairs are pretty close. C's and G's have the most, with T having the least. Overall it is a pretty nice distribution to work with.\n",
    "\n",
    "### II: Processing the Dna Sequence into an array and determining similarity\n",
    "\n",
    "The two sequences that need to be compared, and the split size are passed into the create_dna_array function. The amount of timesteps and samples are calculated in order to properly reshape the data to be passed into the neural networks. An array of zeroes is created to provide an array to be manipulated and allow for vectorization of the base pairs. The array will be shuffled to help prevent overfitting of the neural network. The two sequences will be vectorized and combined in order to be tested for similarity. Finally a similarity score will be awarded to each pair of sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dna_array(sequence_one, sequence_two, timesteps):\n",
    "\n",
    "    # timesteps and samples to determine reshape size\n",
    "    timesteps = timesteps\n",
    "    samples = int(len(sequence_one) / timesteps)\n",
    "    \n",
    "    # Create an array of zeros to be manipulated\n",
    "    array = np.zeros((len(sequence_one),8))\n",
    "    \n",
    "    # mutating the array to effectively vectorize the basepairs.\n",
    "    vectorize_sequence = {'a': 1, 't': 2, 'g': 3, 'c': 4}\n",
    "    \n",
    "    for base in range(len(sequence_one)):\n",
    "        base_one = sequence_one[base]\n",
    "        base_two = sequence_two[base]\n",
    "        array[base, vectorize_sequence[base_one]] = 1\n",
    "        array[base, vectorize_sequence[base_two] + 3] = 1\n",
    "    # shuffle the array to help prevent overfitting\n",
    "    np.random.shuffle(array)\n",
    "    # determine whether sequences are similar or not\n",
    "    similarity_array = np.zeros((len(array),1))\n",
    "    similarity_array = np.asarray([similarity_array[i] == 1 \n",
    "                                   if np.equal(array[i, :4], array[i, 4:]).all() \n",
    "                                   else similarity_array[i] == 0 \n",
    "                                   for i in range(len(array))])\n",
    "    \n",
    "    return np.asarray(array).reshape(samples, timesteps, 8), similarity_array.reshape(samples, timesteps, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III: Creating the population of LSTM networks\n",
    "\n",
    "30 LSTM networks, which will be considered the individuals in this test, will be created as the population. The network consists of three layers. The input layer, an LSTM layer, and a dense layer as the output layer. A tanh function will be used which will give an output between -0.9 and 0.9. 0.9 will be interpreted as having a very high similarity and -0.9 will be the inverse. Bias will also be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population(comparison):\n",
    "    network_population = []\n",
    "    for i in range(30):\n",
    "        model = Sequential()\n",
    "        # add Long short term memory RNN and a dense layer. Compile the model\n",
    "        model.add(LSTM(10, \n",
    "                       input_shape=(comparison.shape[1],8), \n",
    "                       activation='tanh', \n",
    "                       return_sequences=True, \n",
    "                       use_bias=True))\n",
    "        model.add(Dense(1, \n",
    "                        activation='tanh', \n",
    "                        use_bias=True))\n",
    "        network_population.append(model)\n",
    "    return network_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV: Grading the population:\n",
    "\n",
    "The grading function is used to grade the fitness scores of the networks in order to sort the fittest networks from the weakest. For each individual in the population a prediction will be made using the individual network and scored using mean squared error. The networks will then be sorted using argsort. Finally the networks will be split into the nth fittest and weakest models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(pop, inputs, labels, split):\n",
    "    # mse_vec stores the mean squared error score for each network in the population\n",
    "    mse_vec = []\n",
    "    for i in pop:\n",
    "        # make a prediction with each individual\n",
    "        y_pred = i.predict(inputs)\n",
    "        # calculate mean squared error\n",
    "        m_s_e = mse(labels, y_pred)\n",
    "        # keep track of epochs\n",
    "        mse_vec.append(m_s_e)\n",
    "    # convert mse_vec list to array\n",
    "    mse_vec = np.asarray(mse_vec)\n",
    "\n",
    "    # arg sort MSE separate the fittest networks from the weakest.\n",
    "    sorted_mse_idx = np.argsort(mse_vec)\n",
    "    \n",
    "    # set split to allow for various splits\n",
    "    fittest_mse = sorted_mse_idx[:split]\n",
    "    weakest_mse = sorted_mse_idx[split:]\n",
    "\n",
    "    # separate the fittest networks from the weakest.\n",
    "    fittest_models = []\n",
    "    weakest_models = []\n",
    "\n",
    "    for model in fittest_mse:\n",
    "        fittest_models.append(network_population[model])\n",
    "    for model in weakest_mse:\n",
    "        weakest_models.append(network_population[model])\n",
    "    return [fittest_models, weakest_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V: Crossover and Mutate\n",
    "\n",
    "The crossover function is to represent breeding of fit individuals. Simulating reproduction, the fittest individuals will be bred with the weakest individuals, producing offspring with traits from each of the parent individuals. The children will be used to set the new weights for the weakest individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(fittest, weakest, rate):\n",
    "    fittest_weights = fittest.get_weights()\n",
    "    weakest_weights = weakest.get_weights()\n",
    "    boolean_weights = []\n",
    "    # randomly select index's of array to be replaced\n",
    "    for layer in fittest_weights:\n",
    "        boolean_weights.append(bernoulli.rvs(rate, size=layer.shape))\n",
    "    #select weights to take from fittest weights\n",
    "    select_fittest = [random_layer * network_layer + random_layer for \n",
    "                      random_layer, network_layer in zip(boolean_weights, fittest_weights)]\n",
    "    # select weakest weights to kill off\n",
    "    kill_weakest = [(1 - random_layer) * network_layer for \n",
    "                    random_layer, network_layer in zip(boolean_weights, weakest_weights)]\n",
    "    # create the new array of weights by combining the weights from the fittest individuals with\n",
    "    #the weights from the weakest individuals\n",
    "    child_weights = [kill_weakest_layer + select_fittest_layer for \n",
    "                     kill_weakest_layer, select_fittest_layer in zip(select_fittest, kill_weakest)]\n",
    "    \n",
    "    weakest.set_weights(child_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutate is used to emulate a mutation in the wild. All of the weights will either be summed or subtracted with a value from a gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(fittest, weakest, rate):\n",
    "    # get weights\n",
    "    fittest_weights = fittest.get_weights()\n",
    "    weakest_weights = weakest.get_weights()\n",
    "    # addition and subtraction operators\n",
    "    operators = (add, sub)\n",
    "    \n",
    "    # add a random value from a gaussian distributions to the previous weights\n",
    "    for layer in fittest_weights:\n",
    "        operate = np.random.choice(operators)\n",
    "        # select percentage of weights to modify\n",
    "        select_weights = bernoulli.rvs(p=rate, size=layer.shape)\n",
    "        # generate gaussian distribution\n",
    "        random_numbers = np.random.normal(0, 1, layer.shape)\n",
    "        layer[select_weights==1] = operate(random_numbers[select_weights==1], layer[select_weights==1])\n",
    "        \n",
    "    for layer in weakest_weights:\n",
    "        operate = np.random.choice(operators)\n",
    "        select_weights = bernoulli.rvs(p=0.5, size=layer.shape)\n",
    "        random_numbers = np.random.normal(0, 1, layer.shape)\n",
    "        layer[select_weights==1] = operate(random_numbers[select_weights==1], layer[select_weights==1])\n",
    "        \n",
    "    # set the new weights\n",
    "    fittest.set_weights(fittest_weights)\n",
    "    weakest.set_weights(weakest_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI Breeding\n",
    "\n",
    "The breeding function will be used to carry out the simulation of breeding the individuals. For each of the weakest individuals a fit model will be chosen, then the crossover will take place, followed by the mutation. Finally A new child population will be born."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed(fittest, weakest, rate):\n",
    "    for weakest_model in weakest:\n",
    "        #choose random model to take weights from\n",
    "        fittest_model = np.random.choice(fittest)\n",
    "        #crossover weights\n",
    "        crossover(fittest_model, weakest_model, rate)\n",
    "        # add or subtract weight from a gaussian distribution\n",
    "        mutate(fittest_model, weakest_model, rate)    \n",
    "        network_pop = fittest + weakest\n",
    "    return network_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII: Evolve\n",
    "\n",
    "Tying all of the steps together, evolution will take place. First the initial population is generated. The network is then graded and passed through the breeding function, which crosses and mutates the individuals. The children are then set as the new network population. This process will be repeated 30 times and 150 epochs each. The first run will allow for various mutation rates. The first run will also allow for different splits of the fittest and weakest individuals. Each subsequent run will be set at a mutation rate of 50% and the amount of fit networks to keep will be set to 10. After the evolution process has finished, the results will be visualized and analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876627\n",
      "0.22868812\n",
      "1.2792648\n",
      "0.43977252\n",
      "0.3658277\n",
      "3.3201003\n",
      "1.6148838\n",
      "0.18470387\n",
      "1.8118738\n",
      "0.18484978\n",
      "0.18479116\n",
      "0.18479116\n",
      "0.18465653\n"
     ]
    }
   ],
   "source": [
    "# set the network population to the original generated network population\n",
    "network_population = []\n",
    "graph_mse = []\n",
    "mutate_rate = []\n",
    "split_rate = []\n",
    "for run in range(30):\n",
    "    # set mutation rate to 50% and split rate to the 10th index\n",
    "    rate = .5\n",
    "    split = 9\n",
    "    # create the data shuffling it each run.\n",
    "    comparison, similarity_array = create_dna_array(dna_basepairs[:150000], dna_basepairs[5000:155000], 100)\n",
    "    \n",
    "    # create the initial population\n",
    "    if run == 0:\n",
    "        network_population = create_population(comparison)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # run 150 epochs\n",
    "    for epoch in range(149):\n",
    "        # grade the network population and breed it\n",
    "\n",
    "        grade_network = grade(network_population, comparison, similarity_array, split)\n",
    "        breed_networks = breed(grade_network[0],grade_network[1],rate)\n",
    "        # set the network population to the new offspring\n",
    "        network_population = breed_networks\n",
    "\n",
    "        # add the top network score to a list for each epoch to be plotted\n",
    "        y_pred = network_population[0].predict(comparison)\n",
    "        m_s_e = mse(similarity_array, y_pred)\n",
    "        graph_mse.append(m_s_e)\n",
    "        print(m_s_e)\n",
    "        \n",
    "        # for the first run and every 10th epoch select a random mutation and split rate\n",
    "        if run == 0 and epoch % 10:\n",
    "            rate = np.random.choice(np.arange(0.1, 0.9, .1))\n",
    "            split = np.random.choice(np.arange(5, 25, 1))\n",
    "            mutate_rate.append(rate)\n",
    "            split_rate.append(split)\n",
    "            \n",
    "    # for every 5 runs print run\n",
    "    if run % 5:\n",
    "        print(run)\n",
    "\n",
    "# graph the Mean Squared error of the top networks through each epoch.\n",
    "plt.plot(graph_mse)\n",
    "plt.title('Mean Squared Error')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\" Some text about how the graph looks and how the network performed \"\" \n",
    "\n",
    "The output of the best network will be visualized for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the best network on the test data to test for consistency.\n",
    "y_pred = network_population[0].predict(comparison)\n",
    "m_s_e = mse(similarity_array, y_pred)\n",
    "\n",
    "print(y_pred.mean())\n",
    "print('Total Similarity:', total_similarity(similarity_array))\n",
    "print('Mean Squared Error:', m_s_e)\n",
    "\n",
    "# graph the output similarity of the top network.\n",
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], 1))\n",
    "plt.title('Similarity Output')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\" analysis of the graph \"\"\n",
    "\n",
    "### VIII: Importing test sequence\n",
    "The test DNA sequence will be passed in and cleaned and visualized as it was previously, removing the numbers, new lines, and whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dna2.txt', 'r') as myfile:\n",
    "  dna2 = myfile.read()\n",
    "test_basepairs = dna2\n",
    "test_basepairs = re.sub(r'[0-9]([0-9])?([0-9])?([0-9])?([0-9])?([0-9])?', '', test_basepairs)\n",
    "test_basepairs = re.sub(r'\\n', '', test_basepairs)\n",
    "test_basepairs = re.sub(r'\\s+', '', test_basepairs).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepair_graph(test_basepairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX: Processing the data for testing\n",
    "The DNA sequence will be split into four different sets of sequences. The similarity will be variable and will be a good gauge of how the model is performing. The new data will be accessed through lists of the various splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the test sequence comparisons\n",
    "test_comparison_one, test_similarity_one = create_dna_array(test_basepairs[:40000], test_basepairs[:40000], 50)\n",
    "test_comparison_two, test_similarity_two = create_dna_array(test_basepairs[:20000], test_basepairs[:10000] + test_basepairs[20000:30000], 50)\n",
    "test_comparison_three, test_similarity_three = create_dna_array(test_basepairs[1000:16000], test_basepairs[5000:20000], 50)\n",
    "test_comparison_four, test_similarity_four = create_dna_array(test_basepairs[:100000], test_basepairs[50000:150000], 50)\n",
    "\n",
    "# add all the comparison arrays together\n",
    "comparison_tests = [test_comparison_one, \n",
    "                    test_comparison_two, \n",
    "                    test_comparison_three, \n",
    "                    test_comparison_four]\n",
    "# add the labels together\n",
    "similarity_tests = [test_similarity_one, \n",
    "                    test_similarity_two, \n",
    "                    test_similarity_three, \n",
    "                    test_similarity_four]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been successfully cleaned, processed and sorted, it's time to take a look at what the sequences look like. Below is a comparison of the counts of the various basepairs in each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the amount of each basepair in each sequence\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=True, sharey=True,figsize=(12,5))\n",
    "basepair_graph_comparison(test_basepairs[:40000], test_basepairs[:40000], .8, ax1)\n",
    "basepair_graph_comparison(test_basepairs[:20000], test_basepairs[130000:150000], .8, ax2)\n",
    "basepair_graph_comparison(test_basepairs[1000:16000], test_basepairs[5000:20000], .8, ax3)\n",
    "basepair_graph_comparison(test_basepairs[:100000], test_basepairs[50000:150000], .8, ax4)\n",
    "# set the title\n",
    "fig.text(.51, .93, 'Count of Basepairs', ha='center', va='center')\n",
    "# set x label\n",
    "fig.text(0.51, 0.04, 'Basepairs', ha='center', va='center')\n",
    "# set y label\n",
    "fig.text(0.01, 0.5, 'Count', ha='center', va='center', rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X: Test the top model:\n",
    "The data looks good and should provide some interesting results. The model must now prove its worth. First the output average, total similarity, and mean squared error will be displayed for each set of test sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_output = []\n",
    "graph_mse = []\n",
    "# run the best network on the test data to test for consistency.\n",
    "for x in range(4):\n",
    "    y_pred = network_population[0].predict(comparison_tests[x])\n",
    "    m_s_e = mse(similarity_tests[x], y_pred)\n",
    "    graph_output.append(y_pred)\n",
    "    graph_mse.append(m_s_e)\n",
    "    print('Output average:', y_pred.mean())\n",
    "    print('Total Similarity:', total_similarity(similarity_tests[x]))\n",
    "    print('Mean Squared Error:', m_s_e, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\" some text on how the data looks\"\"\n",
    "\n",
    "Next the mean squared error of the networks will be graphed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph the mean squared error of the output on the test data\n",
    "plt.plot(graph_mse)\n",
    "plt.title('Mean Squared Error')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\" some text on how the graph looks\"\"\n",
    "\n",
    "Finally, the ouput similarity will be graphed and examined for each set of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the outputs for all of the networks\n",
    "for x in graph_output:\n",
    "    x = x.reshape(x.shape[0] * x.shape[1], 1)\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(x)\n",
    "    plt.title('Mean Squared Error')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\" some text on how the graph looks\"\"\n",
    "\n",
    "\n",
    "### XI: Discussion and Conclusion:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
