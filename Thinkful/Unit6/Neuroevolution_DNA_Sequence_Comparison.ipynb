{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA Sequence Comparison\n",
    "__October, 2018 - Christopher Sanchez__ \n",
    "\n",
    "Deoxyribonucleic acid, or DNA is a very complex substance that consists of 4 nucleotides known as basepairs. DNA in short is a blue print or algorithm that educates the body on how to create necessary proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/c/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from numpy import argmax, array\n",
    "import keras\n",
    "import tensorflow\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, TimeDistributed, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import bernoulli\n",
    "# Import the backend\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and cleaning the file containing the DNA sequence. It is important to remove the extra numbers, new lines and white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dna.txt', 'r') as myfile:\n",
    "  dna = myfile.read()\n",
    "dna_basepairs = dna\n",
    "dna_basepairs = re.sub(r'[0-9]([0-9])?([0-9])?([0-9])?([0-9])?([0-9])?', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\n', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\s+', '', dna_basepairs).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dna_basepairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population(data):\n",
    "    sequence_one = data[:78122]\n",
    "    sequence_two = data[78123:]\n",
    "    \n",
    "    array = np.zeros((len(sequence_one),8))\n",
    "    vectorize_sequence = {\n",
    "        'a' : 1,\n",
    "        't' : 2,\n",
    "        'g' : 3,\n",
    "        'c' : 4\n",
    "    }\n",
    "\n",
    "    for base in range(len(sequence_one)):\n",
    "        base_one = sequence_one[base]\n",
    "        base_two = sequence_two[base]\n",
    "        array[base, vectorize_sequence[base_one]] = 1\n",
    "        array[base, vectorize_sequence[base_two] + 3] = 1\n",
    "        \n",
    "    similarity_array = np.zeros((len(array),1))\n",
    "    similarity_array = np.asarray([similarity_array[i] == 1 if np.equal(array[i, :4], array[i, 4:]).all() else similarity_array[i] == 0 for i in range(len(array))])\n",
    "        \n",
    "    \n",
    "    return [np.asarray(array).reshape(1, 78122, 8), similarity_array.reshape(1, 78122, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = population(dna_basepairs)\n",
    "comparison = sequences[0].reshape(1, 78122, 8)\n",
    "similarity_array = sequences[1].reshape(1, 78122, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 78122, 8)\n",
      "(1, 78122, 1)\n"
     ]
    }
   ],
   "source": [
    "print(comparison.shape)\n",
    "print(similarity_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I: Creating the population\n",
    "\n",
    "\n",
    "The population of the experiment will consist of 30 LSTM networks with one lstm layer and a dense layer. It will accept an input of 8 input nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_population = []\n",
    "for i in range(30):\n",
    "    model = Sequential()\n",
    "    # add Long short term memory RNN and a dense layer. Compile the model\n",
    "    model.add(LSTM(10, input_shape=(comparison.shape[1],8), activation='tanh', return_sequences=True, use_bias=True))\n",
    "    model.add(Dense(1, activation='tanh', use_bias=True))\n",
    "    network_population.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II: Grading the population:\n",
    "\n",
    "In order to grade the population. The grade function takes in the population of networks, makes a prediction, calculates the mean squared error of the prediction through 150 epochs for each network, and then sorts the fittest networks from the weakest, returning a list that contains the strongest networks, weakest networks and the score of the mean squared error from each network and epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(pop):\n",
    "    mse_vec = []\n",
    "    network_counter = 0\n",
    "    score = dict()\n",
    "    for i in pop:\n",
    "        for n in range(150):\n",
    "        # calculate mean squared error\n",
    "            def mse(y_true, y_pred):\n",
    "                y_true = y_true.reshape(1, y_true.shape[1])\n",
    "                y_pred = y_pred.reshape(1, y_pred.shape[1])\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                return mse\n",
    "            y_pred = i.predict(comparison)\n",
    "            mse = mse(similarity_array, y_pred)\n",
    "            # keep track of epochs\n",
    "            z = str(network_counter) + '_' + str(n)\n",
    "            score[z] = mse\n",
    "        print(network_counter)\n",
    "        network_counter +=1\n",
    "        mse_vec.append(mse)\n",
    "    mse_vec = np.asarray(mse_vec)\n",
    "\n",
    "\n",
    "    # arg sort MSE and separate the fittest networks from the weakest.\n",
    "    sorted_mse_idx = np.argsort(mse_vec)\n",
    "    fittest_mse = sorted_mse_idx[:10]\n",
    "    weakest_mse = sorted_mse_idx[10:]\n",
    "\n",
    "    fittest_models = []\n",
    "    weakest_models = []\n",
    "\n",
    "    for model in fittest_mse:\n",
    "        fittest_models.append(network_population[model])\n",
    "    for model in weakest_mse:\n",
    "        weakest_models.append(network_population[model])\n",
    "    return [fittest_models, weakest_models, score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III: Mutate\n",
    "\n",
    "The crossover function takes the fittest and weakest networks as inputs. First an array of random index's will be selected, then random weights will be selected from the fittest networks at the previously selected random index, and they will be used to replace the index of randomly selected weights from the weakest networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(fittest, weakest):\n",
    "    fittest_weights = fittest.get_weights()\n",
    "    weakest_weights = weakest.get_weights()\n",
    "    random_weights = []\n",
    "    # randomly select index's of array to be replaced\n",
    "    for layer in fittest_weights:\n",
    "        random_weights.append(bernoulli.rvs(.5, size=layer.shape))\n",
    "    #select weights to take from fittest weights\n",
    "    select_fittest = [random_layer * network_layer for random_layer, network_layer in zip(random_weights, fittest_weights)]\n",
    "    # select weakest weights to kill off\n",
    "    kill_weakest = [(1 - random_layer) * network_layer for random_layer, network_layer in zip(random_weights, weakest_weights)]\n",
    "    # create the new array of weights by combining the weights from the fittest models with the weights from the weakest models\n",
    "    new_weights = [kill_weakest_layer + select_fittest_layer for kill_weakest_layer, select_fittest_layer in zip(select_fittest, kill_weakest)]\n",
    "    weakest.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV: Breed\n",
    "\n",
    "A network from each of the networks will be selected to act as partents. The crossover function will then be used to mutate the networks, thereby breeding new networks. The newest mutated population will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed(fittest, weakest):\n",
    "    for weakest_model in weakest:\n",
    "        #choose random model to take weights from\n",
    "        fittest_model = np.random.choice(fittest)\n",
    "        #crossover weights\n",
    "        crossover(fittest_model, weakest_model)\n",
    "    network_population = fittest + weakest\n",
    "    return network_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V: Evolve\n",
    "\n",
    "The genetic algorithm will be ran 30 times. First it will grade the network population, then breed the population. After the population has been bred the network population will be updated to reflect the newest networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "network_population = network_population\n",
    "for x in range(3):\n",
    "    grade_network = grade(network_population)\n",
    "    breed_networks = breed(grade_network[0], grade_network[1])\n",
    "    network_population = breed_networks\n",
    "    def mse(y_true, y_pred):\n",
    "        y_true = y_true.reshape(1, y_true.shape[1])\n",
    "        y_pred = y_pred.reshape(1, y_pred.shape[1])\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        return mse\n",
    "\n",
    "    y_pred = network_population[0].predict(comparison)\n",
    "    mse = mse(similarity_array, y_pred)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_population[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "        y_true = y_true.reshape(1, y_true.shape[1])\n",
    "        y_pred = y_pred.reshape(1, y_pred.shape[1])\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        return mse\n",
    "\n",
    "y_pred = network_population[0].predict(comparison)\n",
    "mse = mse(similarity_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validate, test = np.split(sequences, [int(.5*len(sequences)), int(.75*len(sequences))])\n",
    "#view the various lengths of the split data.\n",
    "#print('Train length:', len(train), '\\n', 'Test length:', len(test), '\\n', 'Validation length:', len(validate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
