{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/c/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from numpy import argmax, array\n",
    "import keras\n",
    "import tensorflow\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, TimeDistributed, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import bernoulli\n",
    "# Import the backend\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dna.txt', 'r') as myfile:\n",
    "  dna = myfile.read()\n",
    "dna_basepairs = dna\n",
    "dna_basepairs = re.sub(r'[0-9]([0-9])?([0-9])?([0-9])?([0-9])?([0-9])?', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\n', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\s+', '', dna_basepairs).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create population of arrays that span 50 index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population(data):\n",
    "    sequence_one = data[:78122]\n",
    "    sequence_two = data[78123:]\n",
    "    \n",
    "    array = np.zeros((len(sequence_one),8))\n",
    "    vectorize_sequence = {\n",
    "        'a' : 1,\n",
    "        't' : 2,\n",
    "        'g' : 3,\n",
    "        'c' : 4\n",
    "    }\n",
    "\n",
    "    for base in range(len(sequence_one)):\n",
    "        base_one = sequence_one[base]\n",
    "        base_two = sequence_two[base]\n",
    "        array[base, vectorize_sequence[base_one]] = 1\n",
    "        array[base, vectorize_sequence[base_two] + 3] = 1\n",
    "        \n",
    "    similarity_array = np.zeros((len(array),1))\n",
    "    similarity_array = np.asarray([similarity_array[i] == 1 if np.equal(array[i, :4], array[i, 4:]).all() else similarity_array[i] == 0 for i in range(len(array))])\n",
    "        \n",
    "    \n",
    "    return [np.asarray(array).reshape(1, 78122, 8), similarity_array.reshape(1, 78122, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = population(dna_basepairs)\n",
    "comparison = sequences[0].reshape(1, 78122, 8)\n",
    "similarity_array = sequences[1].reshape(1, 78122, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 78122, 8)\n",
      "(1, 78122, 1)\n"
     ]
    }
   ],
   "source": [
    "print(comparison.shape)\n",
    "print(similarity_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looping through previous and current index of the population in order to pass each sequence through the RNN for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_population = []\n",
    "for i in range(30):\n",
    "    model = Sequential()\n",
    "    # add Long short term memory RNN and a dense layer. Compile the model\n",
    "    model.add(LSTM(10, input_shape=(comparison.shape[1],8), activation='tanh', return_sequences=True, use_bias=True))\n",
    "    model.add(Dense(1, activation='tanh', use_bias=True))\n",
    "    network_population.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(pop):\n",
    "    mse_vec = []\n",
    "    for i in network_population:\n",
    "        # calculate mean squared error\n",
    "        def mse(y_true, y_pred):\n",
    "            y_true = y_true.reshape(1, y_true.shape[1])\n",
    "            y_pred = y_pred.reshape(1, y_pred.shape[1])\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            return mse\n",
    "\n",
    "        y_pred = i.predict(comparison)\n",
    "        mse = mse(similarity_array, y_pred)\n",
    "        mse_vec.append(mse)\n",
    "    mse_vec = np.asarray(mse_vec)\n",
    "\n",
    "\n",
    "    # arg sort MSE and separate the fittest networks from the weakest.\n",
    "    sorted_mse_idx = np.argsort(mse_vec)\n",
    "    fittest_mse = sorted_mse_idx[:10]\n",
    "    weakest_mse = sorted_mse_idx[10:]\n",
    "\n",
    "    fittest_models = []\n",
    "    weakest_models = []\n",
    "\n",
    "    for model in fittest_mse:\n",
    "        fittest_models.append(network_population[model])\n",
    "    for model in weakest_mse:\n",
    "        weakest_models.append(network_population[model])\n",
    "    return [fittest_models, weakest_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(fittest, weakest):\n",
    "    fittest_weights = fittest.get_weights()\n",
    "    weakest_weights = weakest.get_weights()\n",
    "    random_weights = []\n",
    "    # randomly select index's of array to be replaced\n",
    "    for layer in fittest_weights:\n",
    "        random_weights.append(bernoulli.rvs(.5, size=layer.shape))\n",
    "    #select weights to take from fittest weights\n",
    "    select_fittest = [random_layer * network_layer for random_layer, network_layer in zip(random_weights, fittest_weights)]\n",
    "    # select weakest weights to kill off\n",
    "    kill_weakest = [(1 - random_layer) * network_layer for random_layer, network_layer in zip(random_weights, weakest_weights)]\n",
    "    # create the new array of weights by combining the weights from the fittest models with the weights from the weakest models\n",
    "    new_weights = [kill_weakest_layer + select_fittest_layer for kill_weakest_layer, select_fittest_layer in zip(select_fittest, kill_weakest)]\n",
    "    weakest.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed(fittest, weakest):\n",
    "    for weakest_model in weakest:\n",
    "        #choose random model to take weights from\n",
    "        fittest_model = np.random.choice(fittest)\n",
    "        #crossover weights\n",
    "        crossover(fittest_model, weakest_model)\n",
    "    network_population = fittest + weakest\n",
    "    return network_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_population = network_population\n",
    "for x in range(30):\n",
    "    grade_network = grade(network_population)\n",
    "    breed_networks = breed(grade_network[0], grade_network[1])\n",
    "    network_population = breed_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (None, 78122, 10)         760       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 78122, 1)          11        \n",
      "=================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_population[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a230c0e48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "        y_true = y_true.reshape(1, y_true.shape[1])\n",
    "        y_pred = y_pred.reshape(1, y_pred.shape[1])\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        return mse\n",
    "\n",
    "y_pred = network_population[0].predict(comparison)\n",
    "mse = mse(similarity_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15871038"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validate, test = np.split(sequences, [int(.5*len(sequences)), int(.75*len(sequences))])\n",
    "#view the various lengths of the split data.\n",
    "#print('Train length:', len(train), '\\n', 'Test length:', len(test), '\\n', 'Validation length:', len(validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
