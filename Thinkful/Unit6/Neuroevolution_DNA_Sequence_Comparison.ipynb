{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNA Sequence Comparison\n",
    "__October, 2018 - Christopher Sanchez__ \n",
    "\n",
    "Deoxyribonucleic acid, or DNA is a double helix shaped structure consisting of a chain of nucleotides known as basepairs that act like an algorithm, providing a list of instructions for your body to create proteins. There are four distinct bases A, T, C and G. A always bonds with T and C always bonds with G. A wide variety of information can be gained from DNA analysis. It is possible to determine gender, disease susceptibility, familial ties, DNA is responsible for solving countless amounts of crime, and more! There are multiple sequencing techniques out there, but not all are great for error. I was inspired by this paper: https://www.cse.unr.edu/~cheung/neorgene.pdf, to attempt improving the dna sequencing techniques that are used today. A LSTM RNN is perfect for the task, because it works well with error. A human genome consists of six billion basepairs mistakes are going to be made. It isn't uncommon for a basepair to get switched around. It is important to use a technique that can operate quickly and accurately. \n",
    "\n",
    "Genetic algorithms are very interesting. They work by mimicing the darwin evolutionary theory. Genetic algorithms are similar to a brute force technique, but operate much faster. A genetic algorithm will be used to train a recurrent neural network rather than back propagation. First a population is created, in this case it will be 30 LSTM Recurrent neural networks. The second step is to determine a fitness score, to determine whether a network is worth keeping or not. Next it is important to grade or sort the networks into fit and unfit categories, the 10 fittest networks will be kept and the 20 weakest networks will be killed off. Finally the networks must be bred and evolved. The population will be given a fitness score which is the mean squared error, sorted from fittest to weakest, the top 10 fittest networks will be kept. The weights from the 10 fittest networks will be used to create 20 new networks. The process will be repeated until the desired score is met. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/c/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from numpy import argmax, array\n",
    "import keras\n",
    "import tensorflow\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, TimeDistributed, SimpleRNN\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import bernoulli\n",
    "# Import the backend\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and cleaning the file containing the DNA sequence. It is important to remove the extra numbers, new lines and white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dna.txt', 'r') as myfile:\n",
    "  dna = myfile.read()\n",
    "dna_basepairs = dna\n",
    "dna_basepairs = re.sub(r'[0-9]([0-9])?([0-9])?([0-9])?([0-9])?([0-9])?', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\n', '', dna_basepairs)\n",
    "dna_basepairs = re.sub(r'\\s+', '', dna_basepairs).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dna_basepairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population(data, timesteps):\n",
    "    sequence_one = data[:75000]\n",
    "    sequence_two = data[75000:150000]\n",
    "    # timesteps and samples to determine reshape size\n",
    "    timesteps = timesteps\n",
    "    samples = int(len(sequence_one) / timesteps)\n",
    "    \n",
    "    # Create an array of zeros to be manipulated\n",
    "    array = np.zeros((len(sequence_one),8))\n",
    "    \n",
    "    # mutating the array to effectively vectorize the basepairs.\n",
    "    vectorize_sequence = {'a': 1, 't': 2, 'g': 3, 'c': 4}\n",
    "\n",
    "    for base in range(len(sequence_one)):\n",
    "        base_one = sequence_one[base]\n",
    "        base_two = sequence_two[base]\n",
    "        array[base, vectorize_sequence[base_one]] = 1\n",
    "        array[base, vectorize_sequence[base_two] + 3] = 1\n",
    "    \n",
    "    # determine whether sequences are similar or not\n",
    "    similarity_array = np.zeros((len(array),1))\n",
    "    similarity_array = np.asarray([similarity_array[i] == 1 if np.equal(array[i, :4], array[i, 4:]).all() else similarity_array[i] == 0 for i in range(len(array))])\n",
    "        \n",
    "    \n",
    "    return np.asarray(array).reshape(samples, timesteps, 8), similarity_array.reshape(samples, timesteps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 50, 8) (1500, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "# Creating the data\n",
    "comparison, similarity_array = population(dna_basepairs, 50)\n",
    "\n",
    "print(comparison.shape, similarity_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I: Creating the population\n",
    "\n",
    "\n",
    "The population of the experiment will consist of 30 LSTM networks with one lstm layer and a dense layer. It will accept an input of 8 input nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_population = []\n",
    "for i in range(30):\n",
    "    model = Sequential()\n",
    "    # add Long short term memory RNN and a dense layer. Compile the model\n",
    "    model.add(LSTM(10, input_shape=(comparison.shape[1],8), activation='tanh', return_sequences=True, use_bias=True))\n",
    "    model.add(Dense(1, activation='tanh', use_bias=True))\n",
    "    network_population.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II: Grading the population:\n",
    "\n",
    "In order to grade the population. The grading function takes in the population of networks, makes a prediction, calculates the mean squared error of the prediction through 150 epochs for each network, and then sorts the fittest networks from the weakest, returning a list that contains the strongest networks, weakest networks and the score of the mean squared error from each network and epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade(pop):\n",
    "    mse_vec = []\n",
    "    network_counter = 0\n",
    "    score = dict()\n",
    "    for i in pop:\n",
    "        for n in range(150):\n",
    "        # calculate mean squared error\n",
    "            def mse(y_true, y_pred):\n",
    "                y_true = y_true.reshape(y_true.shape[0], y_true.shape[1])\n",
    "                y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                return mse\n",
    "            y_pred = i.predict(comparison)\n",
    "            mse = mse(similarity_array, y_pred)\n",
    "            # keep track of epochs\n",
    "            z = str(network_counter) + '_' + str(n)\n",
    "            score[z] = mse\n",
    "        network_counter +=1\n",
    "        mse_vec.append(mse)\n",
    "    mse_vec = np.asarray(mse_vec)\n",
    "\n",
    "\n",
    "    # arg sort MSE and separate the fittest networks from the weakest.\n",
    "    sorted_mse_idx = np.argsort(mse_vec)\n",
    "    fittest_mse = sorted_mse_idx[:10]\n",
    "    weakest_mse = sorted_mse_idx[10:]\n",
    "\n",
    "    fittest_models = []\n",
    "    weakest_models = []\n",
    "\n",
    "    for model in fittest_mse:\n",
    "        fittest_models.append(network_population[model])\n",
    "    for model in weakest_mse:\n",
    "        weakest_models.append(network_population[model])\n",
    "    return [fittest_models, weakest_models, score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III: Mutate\n",
    "\n",
    "The crossover function takes the fittest and weakest networks as inputs. First an array of random index's will be selected, then random weights will be selected from the fittest networks at the previously selected random index, and they will be used to replace the index of randomly selected weights from the weakest networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(fittest, weakest):\n",
    "    fittest_weights = fittest.get_weights()\n",
    "    weakest_weights = weakest.get_weights()\n",
    "    random_weights = []\n",
    "    # randomly select index's of array to be replaced\n",
    "    for layer in fittest_weights:\n",
    "        random_weights.append(bernoulli.rvs(.5, size=layer.shape))\n",
    "    #select weights to take from fittest weights\n",
    "    select_fittest = [random_layer * network_layer for random_layer, network_layer in zip(random_weights, fittest_weights)]\n",
    "    # select weakest weights to kill off\n",
    "    kill_weakest = [(1 - random_layer) * network_layer for random_layer, network_layer in zip(random_weights, weakest_weights)]\n",
    "    # create the new array of weights by combining the weights from the fittest models with the weights from the weakest models\n",
    "    new_weights = [kill_weakest_layer + select_fittest_layer for kill_weakest_layer, select_fittest_layer in zip(select_fittest, kill_weakest)]\n",
    "    weakest.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV: Breed\n",
    "\n",
    "A network from each of the networks will be selected to act as partents. The crossover function will then be used to mutate the networks, thereby breeding new networks. The newest mutated population will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed(fittest, weakest):\n",
    "    for weakest_model in weakest:\n",
    "        #choose random model to take weights from\n",
    "        fittest_model = np.random.choice(fittest)\n",
    "        #crossover weights\n",
    "        crossover(fittest_model, weakest_model)\n",
    "    network_population = fittest + weakest\n",
    "    return network_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V: Evolve\n",
    "\n",
    "The genetic algorithm will be ran 30 times. First it will grade the network population, then breed the population. After the population has been bred the network population will be updated to reflect the newest networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32097235\n",
      "0.32097235\n",
      "0.32097235\n",
      "0.28772146\n",
      "0.28772146\n",
      "0.28772146\n",
      "0.205259\n",
      "0.205259\n",
      "0.205259\n",
      "0.205259\n",
      "0.205259\n",
      "0.205259\n",
      "0.205259\n",
      "0.205259\n",
      "0.1912232\n",
      "0.1912232\n",
      "0.1912232\n",
      "0.18442999\n",
      "0.18442999\n",
      "0.18149823\n",
      "0.18149823\n",
      "0.16982487\n",
      "0.16943939\n",
      "0.16943939\n",
      "0.16629969\n",
      "0.1623096\n",
      "0.1623096\n",
      "0.16065644\n",
      "0.15872239\n",
      "0.15696207\n"
     ]
    }
   ],
   "source": [
    "network_population = network_population\n",
    "for x in range(30):\n",
    "    grade_network = grade(network_population)\n",
    "    breed_networks = breed(grade_network[0], grade_network[1])\n",
    "    network_population = breed_networks\n",
    "    def mse(y_true, y_pred):\n",
    "        y_true = y_true.reshape(y_true.shape[0], y_true.shape[1])\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        return mse\n",
    "\n",
    "    y_pred = network_population[0].predict(comparison)\n",
    "    mse = mse(similarity_array, y_pred)\n",
    "    print(mse)+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 50, 10)            760       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50, 1)             11        \n",
      "=================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_population[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a24d5f748>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "        y_true = y_true.reshape(y_true.shape[0], y_true.shape[1])\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        return mse\n",
    "\n",
    "y_pred = network_population[0].predict(comparison)\n",
    "mse = mse(similarity_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15696207"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, validate, test = np.split(sequences, [int(.5*len(sequences)), int(.75*len(sequences))])\n",
    "#view the various lengths of the split data.\n",
    "#print('Train length:', len(train), '\\n', 'Test length:', len(test), '\\n', 'Validation length:', len(validate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
