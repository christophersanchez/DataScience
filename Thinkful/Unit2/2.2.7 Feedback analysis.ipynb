{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We will be performing sentiment analysis utilizing naive bayes to predict whether customer feedback is positive or negative. I retrieved the data from the UCI Machine Learning database.__\n",
    "-  We will start by seperating the most common positive and negative words respectively.\n",
    "-  We will then test various models using various features to see if we can minimize our error.\n",
    "-  We will test the model using a confusion matrix, train test split, and a cross evaluation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by defining and loading in the data, and labeling the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  feedback\n",
       "0  So there is no way for me to plug it in here i...         0\n",
       "1                        Good case, Excellent value.         1\n",
       "2                             Great for the jawbone.         1\n",
       "3  Tied to charger for conversations lasting more...         0\n",
       "4                                  The mic is great.         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab and process the raw data\n",
    "data = \"amazon_cells_labelled.txt\"\n",
    "amazon_raw = pd.read_csv(data, delimiter= '\\t', header=None)\n",
    "amazon_raw.columns = ['message', 'feedback']\n",
    "amazon_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will separate the positive feedback from the negative feedback, convert it all to lowercase, and print out the most common words for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common negative words: [('waste', 13), ('worst', 13), ('bad', 11), (\"don't\", 11), ('not', 9), ('poor', 9), ('do', 8), ('what', 7), ('money', 7), (\"didn't\", 7)]\n",
      "Most common positive words: [('works', 43), ('great', 30), ('love', 20), ('best', 19), ('nice', 19), ('good', 13), ('working', 9), ('pretty', 8), ('excellent', 8), ('fine', 6)]\n"
     ]
    }
   ],
   "source": [
    "# Creating new dataframes for positive and negative feedback.\n",
    "positive_raw = amazon_raw[amazon_raw['feedback'] == 1]\n",
    "negative_raw = amazon_raw[amazon_raw['feedback'] == 0]\n",
    "\n",
    "# Creating a list of the individual words in the strings.\n",
    "positive_words = []\n",
    "negative_words = []\n",
    "for x in positive_raw['message']:\n",
    "    split = x.split()\n",
    "    positive_words = positive_words + split\n",
    "\n",
    "for x in negative_raw['message']:\n",
    "    split = x.split()\n",
    "    negative_words = negative_words + split\n",
    "\n",
    "# Using set's to determine common words in each of the lists.\n",
    "intersect = list(set(positive_words) & set(negative_words))\n",
    "\n",
    "for x in intersect:\n",
    "    while x in positive_words:\n",
    "        positive_words.remove(x)\n",
    "    while x in negative_words:\n",
    "        negative_words.remove(x)\n",
    "        \n",
    "# Converting the words to lowercase\n",
    "positive_words = [x.lower() for x in positive_words]\n",
    "negative_words = [x.lower() for x in negative_words]\n",
    "\n",
    "# Getting a count of the words in each list, and printing the top 10 most common in each.\n",
    "negative_counts = Counter(negative_words)\n",
    "positive_counts = Counter(positive_words)    \n",
    "print('Most common negative words:', negative_counts.most_common(10))\n",
    "print('Most common positive words:', positive_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We will start by creating 4 different set of keywords.__\n",
    "-  The first set will contain the top 10 most common negative words.\n",
    "-  The second set will contain the top 10 most common positive words.\n",
    "-  The third set will contain the top 5 positive and the top 5 negative words.\n",
    "-  The fourth set will contain the top 10 most common positive and negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['waste', 'worst', 'bad', 'don\\'t', 'not', 'poor', 'what', 'do', 'money', 'didn\\'t']\n",
    "keywords2 = ['works', 'great', 'love', 'best', 'nice', 'good', 'working', 'pretty', 'excellent', 'fine']\n",
    "keywords3 = ['works', 'great', 'love', 'best', 'nice', 'waste', 'worst', 'bad', 'don\\'t', 'not']\n",
    "keywords4 = ['works', 'great', 'love', 'best', 'nice', 'good', 'working', 'pretty', 'excellent', 'fine', 'waste', 'worst', 'bad', 'don\\'t', 'not', 'poor', 'what', 'do', 'money', 'didn\\'t']\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    amazon_raw[str(key)] = amazon_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "    \n",
    "for key in keywords2:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    amazon_raw[str(key)] = amazon_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "    \n",
    "for key in keywords3:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    amazon_raw[str(key)] = amazon_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "    \n",
    "for key in keywords4:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    amazon_raw[str(key)] = amazon_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create our first model using the first set of keywords which contains the top 10 negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 386\n"
     ]
    }
   ],
   "source": [
    "data = amazon_raw[keywords]\n",
    "target = amazon_raw['feedback']\n",
    "\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using just the top 10 negative words we were able to classify 614 points out of 1000. Lets try it using just positive words now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 364\n"
     ]
    }
   ],
   "source": [
    "data2 = amazon_raw[keywords2]\n",
    "\n",
    "bnb.fit(data2, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data2)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data2.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to lower the points even more using just the positive words. We classified 636 out of 1000 words. Below we will run the same test again with the top 5 positive and top 5 negative keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 402\n"
     ]
    }
   ],
   "source": [
    "data3 = amazon_raw[keywords3]\n",
    "\n",
    "bnb.fit(data3, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data3)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data3.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly using a mix of the two caused there to be only 598 points identified. Lets explore deeper by using the top 10 most common positive and negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 364\n"
     ]
    }
   ],
   "source": [
    "data4 = amazon_raw[keywords4]\n",
    "\n",
    "bnb.fit(data4, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data4)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data4.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the top 10 of positive and negative words produced the same quality of classification as using just the top 10 positive words. Lets try using count vectorizer to see what kind of results we can get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin building our model, fitting it to the data and displaying the result. Using countvectorizer and fit transform to tokenize the words in the message column thereby transforming the string into numeric values. It will then add up all the values and get a count of occurences of each value. I will then display the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 41\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(amazon_raw['message'].values)\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "targets = amazon_raw['feedback'].values\n",
    "classifier.fit(counts,targets)\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = classifier.predict(counts)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    counts.shape[0],\n",
    "    (targets != y_pred).sum()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will examine the model using a confusion matrix, train test split, and k cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[468  32]\n",
      " [  9 491]]\n",
      "With 20% Holdout: 0.84\n",
      "Testing on Sample: 0.959\n",
      "K cross validation score: 0.8160000000000001\n"
     ]
    }
   ],
   "source": [
    "# Display a confusion matrix to visualize our prediction results.\n",
    "print('Confusion Matrix:', confusion_matrix(targets, y_pred))\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, targets, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(classifier.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(classifier.fit(counts, targets).score(counts, targets)))\n",
    "\n",
    "# Use K Cross Validation to further examine how valid our model is.\n",
    "bnbcross = cross_val_score(classifier, counts, targets, cv=10)\n",
    "print('K cross validation score:', bnbcross.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bernoulli classifier earns a B. It identified 468 out of 500 negatives, giving a specificity score of 94%, and 491 out of 500 positives givining it a specificity score of 98%.  it had a 96% accuracy rate on the entire sample, but only a 84% rate of accuracy on the train test using a 20% holdout. Using cross validation it has a rate of nearly 82%. There is some overfitting going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will repeat the process above this time using a multinomial classifier to see how the results differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 35\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(amazon_raw['message'].values)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "targets = amazon_raw['feedback'].values\n",
    "mnb.fit(counts,targets)\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = mnb.predict(counts)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    counts.shape[0],\n",
    "    (targets != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[476  24]\n",
      " [ 11 489]]\n",
      "With 20% Holdout: 0.825\n",
      "Testing on Sample: 0.965\n",
      "K cross validation score: 0.8169999999999998\n"
     ]
    }
   ],
   "source": [
    "# Display a confusion matrix to visualize our prediction results.\n",
    "print('Confusion Matrix:', confusion_matrix(targets, y_pred))\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, targets, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(mnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(mnb.fit(counts, targets).score(counts, targets)))\n",
    "\n",
    "# Use K Cross Validation to further examine how valid our model is.\n",
    "mnbcross = cross_val_score(mnb, counts, targets, cv=10)\n",
    "print('K cross validation score:', mnbcross.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the multionomial classifier appears to be slight superior boasting a higher negative prediction rate. This model has a specifiticy score of 95% and a sensitivity score of 98%. The train test and k validation score are quite similar. There does still appear to be some overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
