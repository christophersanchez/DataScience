{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make your network\n",
    "__July, 2018 - By: Christopher Sanchez__\n",
    "\n",
    "Hello, thanks for stopping by. Today we have a few goals that we are going to accomplish. We will build a multi-layer perceptron neural network model to predict on a labeled dataset that we will find online. We will build the best model we can, by diving into the hyperparameters and discovering the best combination for our data. We will then compare our perceptron model to a boosted tree model to examine the efficiencies of both, and determine which model better solves our output question. We will check for complexity and accuracy.\n",
    "\n",
    "__Our checklist:__\n",
    "- Find a dataset\n",
    "- Introduce our dataset\n",
    "- Import our necessary modules, and the data\n",
    "- Examine the data to get a better understanding of our data\n",
    "- Clean and process the data\n",
    "- Build our models\n",
    "- Conclude by comparing and contrasting our two models.\n",
    "\n",
    "The dataset we will be tearing into today is an interesting bank marketing dataset graciously hosted over at UCI. You can find it here. It is a dataset representing data collected from direct marketing campaigns of a Portuguese banking institution. The dataset consists of 41,188 rows and 21 columns which will represent our features. Clients received multiple contacts often. The question we will be trying to answer with the data is whether or not a client will subscribe a term deposit. Time to dig in! Let’s start by discussing and importing the modules (library that allows us to use advanced functions) we’re going to need.\n",
    "\n",
    "__Modules that we will use:__\n",
    "- Numpy\n",
    "- Pandas\n",
    "- SKlearn\n",
    "- Operator\n",
    "- Time\n",
    "\n",
    "Numpy is an excellent library and it allows us to compute numerous advanced mathematical functions, work with arrays, and much more. \n",
    "\n",
    "Pandas is built off of the Numpy library, and allows us to work with the data in a more structured manner. Pandas allows you to use data frames, and manipulate them in various ways.\n",
    "\n",
    "Sklearn is a great package. It is very powerful and it is the library that we will use to build our models today. We will use various clustering techniques and machine learning techniques utilizing SKlearn.\n",
    "\n",
    "The operator module allows us to use more efficient functions to perform our operations.\n",
    "\n",
    "The time module will allow us to see how long our models are taking to computer.\n",
    "\n",
    "\n",
    "Great let’s start building.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "import operator\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the imports that we’re going to use which we previously discussed. We will also set some display options that will allow us to better view the data. \n",
    "\n",
    "Let’s import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact month day_of_week  duration  campaign  pdays  previous     poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   may         mon       261         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
       "1   57   services  married  high.school  unknown      no   no  telephone   may         mon       149         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
       "2   37   services  married  high.school       no     yes   no  telephone   may         mon       226         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   may         mon       151         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
       "4   56   services  married  high.school       no      no  yes  telephone   may         mon       307         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bankmarketing.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great our data is imported and the only modifications we had to make were, splitting the data using a semi-colon,\n",
    "\n",
    "Now let’s take a quick dive into the data and look at the shape, nulls and data types of our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      " (41188, 21) \n",
      "\n",
      "Nulls:\n",
      " age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64 \n",
      "\n",
      "Data types:\n",
      " age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "y                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Shape:\\n',df.shape,'\\n')\n",
    "print('Nulls:\\n', df.isnull().sum(),'\\n')\n",
    "print('Data types:\\n', df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great so we can see that we are working with 41,000 rows and 21 features. There are also no nulls. However all of our data types are different and we need to convert all of our data to numerical. Let’s get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "categorical_features = ['age', 'job', 'marital', 'education', 'default', 'housing',\n",
    "                        'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n",
    "for category in categorical_features:\n",
    "    counter = 0\n",
    "    for x in df[category].unique():\n",
    "        df[category] = df[category].replace(x, counter)\n",
    "        counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  month  day_of_week  duration  campaign  pdays  previous  poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y\n",
       "0    0    0        0          0        0        0     0        0      0            0       261         1    999         0         0           1.1          93.994          -36.4      4.857       5191.0  0\n",
       "1    1    1        0          1        1        0     0        0      0            0       149         1    999         0         0           1.1          93.994          -36.4      4.857       5191.0  0\n",
       "2    2    1        0          1        0        1     0        0      0            0       226         1    999         0         0           1.1          93.994          -36.4      4.857       5191.0  0\n",
       "3    3    2        0          2        0        0     0        0      0            0       151         1    999         0         0           1.1          93.994          -36.4      4.857       5191.0  0\n",
       "4    0    1        0          1        0        0     1        0      0            0       307         1    999         0         0           1.1          93.994          -36.4      4.857       5191.0  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we created a for loop to loop through a list of our categorical features, giving all of our data points a numerical value. \n",
    "\n",
    "Time to split our data set up. We will create our input variable and our output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['y'], 1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X will represent our input variables, and y will be our outcome. \n",
    "\n",
    "Now lets process the data. It is important that we normalize our data to give us a normal distribution which will eliminate some variance and redundancy. We will also make sure everything is numerical. Finally we will split our data in order for us to train our model on the training data, and test it on the testing data to ensure there is no overfitting going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors = 'coerce')\n",
    "X = preprocessing.normalize(X)\n",
    "X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. Our input variables X has been processed and is ready to fire on all cylinders. The split has also been executed successfully. Our train size is 67% of the data and our testing set is 33%. \n",
    "\n",
    "Let’s start building our first neural network. We will use Sklearns MLPClassifier. We will use 5 hidden networks, and start off with the ‘relu’ activation function which is usually the best in my experience.We will time our model to determine how long it takes to fit the data. Next we will print out a cross validation score on the test data to see how well our model performed, and to determine whether or not there is any overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0:08:13.911743\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "\n",
    "mlp_relu = MLPClassifier(hidden_layer_sizes=(1000, 1000, 1000, 1000, 1000), activation='relu')\n",
    "mlp_relu.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now fit to our model. Look at the time though with 67% of the data it took over 8 minutes to fit the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89959544 0.91062891 0.91798455 0.90327326 0.9076187 ]\n",
      "Time: 0:49:32.707731\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "\n",
    "print(cross_val_score(mlp_relu, X_test, y_test, cv=5))\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function worked pretty well. We were able to achieve an average of 90% across our cross validation test. It looks like there wasn’t any overfitting happening. It took 38 and a half minutes to run our cross validation test on our test data, which is only 33% of the data. \n",
    "Now let’s compare our relu model with a tanh model. Without further ado I give you, our tanh model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0:23:34.447781\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "mlp_tanh = MLPClassifier(hidden_layer_sizes=(1000, 1000, 1000, 1000, 1000), activation='tanh')\n",
    "mlp_tanh.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tanh model took nearly three times as longer than our relu model to fit our data. Hopefully the performance was worth the wait. Let's check it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90069879 0.90805443 0.91136447 0.90511217 0.8951049 ]\n",
      "Time: 0:38:22.637670\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "print(cross_val_score(mlp_tanh, X_test, y_test, cv=5))\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our relu model is a slightly better fit than our tanh model. It's not a bad thing though, since the time to fit was much less. \n",
    "\n",
    "What about the sigmoid function, also known as logistic? Let’s see how it performs now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0:04:31.612431\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "mlp_logistic = MLPClassifier(hidden_layer_sizes=(1000, 1000, 1000, 1000, 1000), activation='logistic')\n",
    "mlp_logistic.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Our resident speedy Gonzales appeared. It only took four and a half minutes to fit the data using the logistic function. I’m intrigued to see how it is going to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88856197 0.88856197 0.88856197 0.88856197 0.88884799]\n",
      "Time: 0:11:39.000124\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "print(cross_val_score(mlp_logistic, X_test, y_test, cv=5))\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fast performer here too. It did decently well, but there is a big drop off from our relu and tanh models. \n",
    "Now let’s take a look at our final model. Our boosted trees classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0:00:09.370913\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "gbr = GradientBoostingClassifier(**params)\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our boosted trees model performed extremely quickly only taking nine seconds to run, but how well did it do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91026113 0.91945568 0.92092681 0.91651342 0.91534781]\n",
      "Time: 0:00:17.656936\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "print(cross_val_score(gbr, X_test, y_test, cv=5))\n",
    "\n",
    "end_time = time.monotonic()\n",
    "print('Time:', timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly our boosted trees model is the most efficient. It has a higher accuracy average and performed quickly. \n",
    "\n",
    "### Discussion and conclusion:\n",
    "All of our models performed well. Our MLP classifier models took a long time to operate. The accuracy scores are satisfactory, but the time was just totally inefficient. Our boosted trees model performed the best, though slightly, it was by far the fastest. \n",
    "\n",
    "I believe the neural network could outperform the boosted trees model, however I don’t have the computational resources to push it to a much higher capacity. Neural networks and boosted trees are both very effective, and have a multitude of parameters that you can adjust to better fit your data, however neural networks are exceptionally computationally expensive and are hard to do much with, unless you have a nicely size server. If working with neural networks, or any computationally expensive algorithm for that matter, I recommend that you work with a smaller chunk of data initially in order to make sure that all of your programming is working correctly and efficiently, and after you have everything programmed, run all of the data through your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
