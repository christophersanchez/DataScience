{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW and Tf-idf NLP Modeling\n",
    "August, 2018 - __Christopher Sanchez__\n",
    "\n",
    "Building a model for natural language processing is a multi step process. Some of the possible steps include: \n",
    "- processing, cleaning and parsing the language data, \n",
    "- creating features using various NLP methods (Bag of words and Tf-idf will be used in this example)\n",
    "- fit supervised learning models to the created features\n",
    "- examine the effectiveness of the models using cross validation\n",
    "- refine the models with the intention of improving the ability of the models.\n",
    "\n",
    "Cell one contains some of the imports that will be used in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the importation of the dataset, and cleaning of the links from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mbti.csv')\n",
    "df['posts'] = df['posts'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display of the head to show the initial visualization of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>' and intj moments    sportscenter not top ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____    course, to which I say I k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  ' and intj moments    sportscenter not top ten...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____    course, to which I say I k...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts is a great way to display the unique class values and the counts of each. If data is too dominated by one class it can be hard to effectively build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    1832\n",
       "INFJ    1470\n",
       "INTP    1304\n",
       "INTJ    1091\n",
       "ENTP     685\n",
       "ENFP     675\n",
       "ISTP     337\n",
       "ISFP     271\n",
       "ENTJ     231\n",
       "ISTJ     205\n",
       "ENFJ     190\n",
       "ISFJ     166\n",
       "ESTP      89\n",
       "ESFP      48\n",
       "ESFJ      42\n",
       "ESTJ      39\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the map function to convert the class categorical variables to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['type'].map({'INFJ':0, 'ENTP':1, 'INTP':2, 'INTJ':3, 'ENTJ':4, 'ENFJ':5, 'INFP':6, 'ENFP':7,\n",
    "       'ISFP':8, 'ISTP':9, 'ISFJ':10, 'ISTJ':11, 'ESTP':12, 'ESFP':13, 'ESTJ':14, 'ESFJ':15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the map function worked as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>' and intj moments    sportscenter not top ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>'Good one  _____    course, to which I say I k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0     0  ' and intj moments    sportscenter not top ten...\n",
       "1     1  'I'm finding the lack of me in these posts ver...\n",
       "2     2  'Good one  _____    course, to which I say I k...\n",
       "3     3  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     4  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the input feature and the output in order to being building the models, starting with bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675,)\n",
      "(8675,)\n"
     ]
    }
   ],
   "source": [
    "X = df['posts']\n",
    "y = df['type']\n",
    "\n",
    "# Display the shape to make sure the length is the same.\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data with the default settings(test set is 25%). It is important to split the data to properly evaluate the model further on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer is an effective way to create the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6506x1500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2261801 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Setting max features to 1500 will choose the 1500 with the highest count.\n",
    "vectorizer = CountVectorizer(max_features=1500)\n",
    "# Train the model and transform it to a sparse matrix with X_train.\n",
    "X_train_matrix = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2169x1500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 757710 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat with \n",
    "X_test_matrix = vectorizer.transform(X_test)\n",
    "X_test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first classifier that will be used is Multinomial Naive Bayes. Naive bayes tends to excel in natural language processing situations. The effectiveness of the classifer will be determined via cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.6474023977866584\n",
      "\n",
      "Test set score: 0.5394190871369294\n",
      "\n",
      "Cross Val score: [0.5260771  0.57665904 0.48036952 0.51740139 0.53395785]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_matrix, y_train)\n",
    "\n",
    "print('Training set score:', mnb.score(X_train_matrix, y_train))\n",
    "print('\\nTest set score:', mnb.score(X_test_matrix, y_test))\n",
    "print('\\nCross Val score:',cross_val_score(mnb, X_test_matrix, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad the model is predicting better than a coin flip. There is some overfitting going on.\n",
    "\n",
    "Random forest is a very powerful and versatile classifier. The process is repeated below, this time with Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9932370119889333\n",
      "\n",
      "Test set score: 0.4181650530198248\n",
      "\n",
      "Cross Val score: [0.34013605 0.36613272 0.3187067  0.33410673 0.33489461]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train_matrix, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_matrix, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test_matrix, y_test))\n",
    "print('\\nCross Val score:',cross_val_score(rfc, X_test_matrix, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model performed much worse than the Naive Bayes model. \n",
    "\n",
    "SpaCy is a powerful package for natural language processing. It is effective at parsing and processing text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Making a copy of the dataframe for editing with spacy.\n",
    "spacy_df = df.copy()\n",
    "\n",
    "# loading spacy \n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lemma is the root of a word, and can make it much easier for a classifier to classify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a lambda function to parse the dataframe with nlp, take the lemma of all words, and remove punctation and stop words.\n",
    "spacy_df['posts'] = spacy_df['posts'].apply(lambda row: [token.lemma_ for token in nlp(row) if not token.is_punct and not token.is_stop])\n",
    "# convert the data back to strings as spacy converts the rows to lists.\n",
    "spacy_df['posts'] = spacy_df['posts'].astype(str).str.replace('\\[|\\]|\\'', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the new head to make sure the data looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>intj, moment,    , sportscenter, play,    , pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-PRON-, be, find, lack, post, alarming.|||sex,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>good,  ,    , course, -PRON-, -PRON-, know, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dear, intp,   , -PRON-, enjoy, conversation, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-PRON-, be, fired.|||that, be, silly, misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0     0  intj, moment,    , sportscenter, play,    , pr...\n",
       "1     1  -PRON-, be, find, lack, post, alarming.|||sex,...\n",
       "2     2  good,  ,    , course, -PRON-, -PRON-, know, be...\n",
       "3     3  dear, intp,   , -PRON-, enjoy, conversation, d...\n",
       "4     4  -PRON-, be, fired.|||that, be, silly, misconce..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate X and y with the new spacy dataframe. Train and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675,)\n",
      "(8675,)\n"
     ]
    }
   ],
   "source": [
    "X = spacy_df['posts']\n",
    "y = spacy_df['type']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_X_train, spacy_X_test, spacy_y_train, spacy_y_test = train_test_split(X, y, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the bag of words with count vectorizer and the new spacy parsed, cleaned, and processed X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6506x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1480270 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "\n",
    "spacy_X_train_matrix = vectorizer.fit_transform(spacy_X_train)\n",
    "\n",
    "spacy_X_train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat with the new X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2169x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 495868 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_X_test_matrix = vectorizer.transform(spacy_X_test)\n",
    "spacy_X_test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Naive Bayes classifier to determine improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.6603135567168767\n",
      "\n",
      "Test set score: 0.5850622406639004\n",
      "\n",
      "Cross Val score: [0.57142857 0.59954233 0.53117783 0.55916473 0.55971897]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(spacy_X_train_matrix, spacy_y_train)\n",
    "\n",
    "print('Training set score:', mnb.score(spacy_X_train_matrix, spacy_y_train))\n",
    "print('\\nTest set score:', mnb.score(spacy_X_test_matrix, spacy_y_test))\n",
    "print('\\nCross Val score:',cross_val_score(mnb, spacy_X_test_matrix, spacy_y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still some overfitting going on, but it did perform better by about 5% accuracy\n",
    "\n",
    "Repeating with Random Forest again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9932370119889333\n",
      "\n",
      "Test set score: 0.4319963116643615\n",
      "\n",
      "Cross Val score: [0.37641723 0.3409611  0.38799076 0.38283063 0.37704918]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(spacy_X_train_matrix, spacy_y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(spacy_X_train_matrix, spacy_y_train))\n",
    "print('\\nTest set score:', rfc.score(spacy_X_test_matrix, spacy_y_test))\n",
    "print('\\nCross Val score:',cross_val_score(rfc, spacy_X_test_matrix, spacy_y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement was slight. Only improving by about 2%. The Random Forest classifier doesn't seem to be a very good model for the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer\n",
    "is another method of feature extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6506x28366 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2100905 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=4, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "# Fit and transform X_train with the tfidf vectorizer.\n",
    "tfidf_X_train_matrix = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "tfidf_X_train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sparse matrix for X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2169x28366 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 699059 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X_test_matrix = tfidf_vectorizer.transform(X_test)\n",
    "tfidf_X_test_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine effectiveness of the tfidf vectorizer with the naive bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.3061789117737473\n",
      "\n",
      "Test set score: 0.24343015214384509\n",
      "\n",
      "Cross Val score: [0.21768707 0.2173913  0.21939954 0.22041763 0.22248244]\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(tfidf_X_train_matrix, y_train)\n",
    "\n",
    "print('Training set score:', mnb.score(tfidf_X_train_matrix, y_train))\n",
    "print('\\nTest set score:', mnb.score(tfidf_X_test_matrix, y_test))\n",
    "print('\\nCross Val score:',cross_val_score(mnb, tfidf_X_test_matrix,y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is doing horribly with only a 24% accuracy rate, though it doesn't seem to be overfitting much.\n",
    "\n",
    "Hopefully the Random Forest classifier below will do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9933907162619121\n",
      "\n",
      "Test set score: 0.334716459197787\n",
      "\n",
      "Cross Val score: [0.29024943 0.30892449 0.30254042 0.27842227 0.35362998]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(tfidf_X_train_matrix, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(tfidf_X_train_matrix, y_train))\n",
    "print('\\nTest set score:', rfc.score(tfidf_X_test_matrix, y_test))\n",
    "print('\\nCross Val score:',cross_val_score(rfc, tfidf_X_test_matrix,y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest classifier did perform better, however it is overfitting.\n",
    "\n",
    "Will spacy improve the quality of the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6506x23566 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1824238 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tfidf_X_train_matrix = tfidf_vectorizer.fit_transform(spacy_X_train)\n",
    "\n",
    "spacy_tfidf_X_train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2169x23566 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 605914 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tfidf_X_test_matrix = tfidf_vectorizer.transform(spacy_X_test)\n",
    "spacy_tfidf_X_test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.3130956040577928\n",
      "\n",
      "Test set score: 0.2512678653757492\n",
      "\n",
      "Cross Val score: [0.21768707 0.2173913  0.21939954 0.22041763 0.22248244]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(spacy_tfidf_X_train_matrix, spacy_y_train)\n",
    "\n",
    "print('Training set score:', mnb.score(spacy_tfidf_X_train_matrix, y_train))\n",
    "print('\\nTest set score:', mnb.score(spacy_tfidf_X_test_matrix, y_test))\n",
    "print('\\nCross Val score:',cross_val_score(mnb, spacy_tfidf_X_test_matrix, spacy_y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy allowed us a very slight improvement, from 24%-25% \n",
    "\n",
    "Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9940055333538272\n",
      "\n",
      "Test set score: 0.3084370677731674\n",
      "\n",
      "Cross Val score: [0.27437642 0.32951945 0.27482679 0.29234339 0.27868852]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(spacy_tfidf_X_train_matrix, spacy_y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(spacy_tfidf_X_train_matrix, y_train))\n",
    "print('\\nTest set score:', rfc.score(spacy_tfidf_X_test_matrix, y_test))\n",
    "print('\\nCross Val score:',cross_val_score(rfc, spacy_tfidf_X_test_matrix, spacy_y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest is actually performing worse with spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and conclusion\n",
    "\n",
    "Bag of words seems to be the more effective of the two feature extraction methods that were used. It was interesting to see that Naive Bayes outperformed the Random Forest being such a simple classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
